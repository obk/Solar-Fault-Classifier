{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 21:11:04.662619: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-02 21:11:04.670924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738519864.680232   81910 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738519864.683222   81910 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-02 21:11:04.693916: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738519874.837858   81910 gpu_device.cc:2022] Created device /device:GPU:0 with 13517 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "#GPU Test\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 474 images belonging to 4 classes.\n",
      "Found 117 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # %20 validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'images_classed',\n",
    "    target_size=(150, 150),  \n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'images_classed',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obk/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738520047.359067   83668 service.cc:148] XLA service 0x7984b0007e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738520047.359087   83668 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4080, Compute Capability 8.9\n",
      "2025-02-02 21:14:07.374121: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738520047.446875   83668 cuda_dnn.cc:529] Loaded cuDNN version 90700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/14\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3524 - loss: 1.8521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738520048.974424   83668 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 307ms/step - accuracy: 0.3378 - loss: 1.7367 - val_accuracy: 0.4688 - val_loss: 1.1164\n",
      "Epoch 2/300\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4062 - loss: 1.2477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obk/anaconda3/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4062 - loss: 1.2477 - val_accuracy: 0.5312 - val_loss: 1.1208\n",
      "Epoch 3/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - accuracy: 0.4419 - loss: 1.2231 - val_accuracy: 0.5417 - val_loss: 1.0829\n",
      "Epoch 4/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.0931 - val_accuracy: 0.4062 - val_loss: 1.2696\n",
      "Epoch 5/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.4813 - loss: 1.1851 - val_accuracy: 0.4688 - val_loss: 1.2434\n",
      "Epoch 6/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3077 - loss: 1.3441 - val_accuracy: 0.4583 - val_loss: 1.1821\n",
      "Epoch 7/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4534 - loss: 1.1975 - val_accuracy: 0.5625 - val_loss: 1.2720\n",
      "Epoch 8/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.2006 - val_accuracy: 0.6250 - val_loss: 1.2289\n",
      "Epoch 9/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.4084 - loss: 1.2257 - val_accuracy: 0.5833 - val_loss: 1.3699\n",
      "Epoch 10/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 1.1032 - val_accuracy: 0.5938 - val_loss: 1.2972\n",
      "Epoch 11/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4291 - loss: 1.2146 - val_accuracy: 0.6146 - val_loss: 1.4140\n",
      "Epoch 12/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.0214 - val_accuracy: 0.6042 - val_loss: 1.2867\n",
      "Epoch 13/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4814 - loss: 1.1714 - val_accuracy: 0.5000 - val_loss: 1.6645\n",
      "Epoch 14/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6250 - loss: 1.0859 - val_accuracy: 0.4792 - val_loss: 1.6345\n",
      "Epoch 15/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4389 - loss: 1.1645 - val_accuracy: 0.5938 - val_loss: 1.4898\n",
      "Epoch 16/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4688 - loss: 1.1343 - val_accuracy: 0.5521 - val_loss: 1.7882\n",
      "Epoch 17/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4670 - loss: 1.1332 - val_accuracy: 0.5729 - val_loss: 1.4655\n",
      "Epoch 18/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4062 - loss: 1.1754 - val_accuracy: 0.5417 - val_loss: 1.5584\n",
      "Epoch 19/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4898 - loss: 1.1365 - val_accuracy: 0.4688 - val_loss: 1.7170\n",
      "Epoch 20/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.2208 - val_accuracy: 0.4896 - val_loss: 1.8226\n",
      "Epoch 21/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4786 - loss: 1.1291 - val_accuracy: 0.5625 - val_loss: 2.3039\n",
      "Epoch 22/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5312 - loss: 1.0792 - val_accuracy: 0.4583 - val_loss: 2.8163\n",
      "Epoch 23/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4422 - loss: 1.1425 - val_accuracy: 0.5729 - val_loss: 2.1676\n",
      "Epoch 24/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5312 - loss: 1.0632 - val_accuracy: 0.5000 - val_loss: 2.9526\n",
      "Epoch 25/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4530 - loss: 1.1234 - val_accuracy: 0.5208 - val_loss: 1.5965\n",
      "Epoch 26/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5312 - loss: 0.9845 - val_accuracy: 0.5000 - val_loss: 1.7619\n",
      "Epoch 27/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4472 - loss: 1.2730 - val_accuracy: 0.4375 - val_loss: 1.4905\n",
      "Epoch 28/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.1225 - val_accuracy: 0.5312 - val_loss: 1.6252\n",
      "Epoch 29/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4548 - loss: 1.1572 - val_accuracy: 0.5104 - val_loss: 1.9664\n",
      "Epoch 30/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.1372 - val_accuracy: 0.5938 - val_loss: 1.8093\n",
      "Epoch 31/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.4484 - loss: 1.1304 - val_accuracy: 0.5521 - val_loss: 2.1830\n",
      "Epoch 32/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.0055 - val_accuracy: 0.5938 - val_loss: 1.6632\n",
      "Epoch 33/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.4640 - loss: 1.1448 - val_accuracy: 0.5938 - val_loss: 2.2289\n",
      "Epoch 34/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 1.0585 - val_accuracy: 0.5417 - val_loss: 2.5917\n",
      "Epoch 35/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.4669 - loss: 1.1153 - val_accuracy: 0.5521 - val_loss: 2.3398\n",
      "Epoch 36/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4688 - loss: 1.0213 - val_accuracy: 0.6146 - val_loss: 2.4166\n",
      "Epoch 37/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4916 - loss: 1.1083 - val_accuracy: 0.5521 - val_loss: 1.7172\n",
      "Epoch 38/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5312 - loss: 1.1602 - val_accuracy: 0.5521 - val_loss: 1.7582\n",
      "Epoch 39/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4393 - loss: 1.1923 - val_accuracy: 0.5729 - val_loss: 1.4647\n",
      "Epoch 40/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 1.0629 - val_accuracy: 0.4479 - val_loss: 1.6633\n",
      "Epoch 41/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4705 - loss: 1.1112 - val_accuracy: 0.3958 - val_loss: 2.0163\n",
      "Epoch 42/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.1665 - val_accuracy: 0.4688 - val_loss: 1.8011\n",
      "Epoch 43/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5289 - loss: 1.0623 - val_accuracy: 0.4479 - val_loss: 2.2427\n",
      "Epoch 44/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.1530 - val_accuracy: 0.5000 - val_loss: 2.2346\n",
      "Epoch 45/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4732 - loss: 1.0866 - val_accuracy: 0.4688 - val_loss: 3.0109\n",
      "Epoch 46/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.0055 - val_accuracy: 0.4167 - val_loss: 3.5082\n",
      "Epoch 47/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.5089 - loss: 1.0971 - val_accuracy: 0.5208 - val_loss: 2.2279\n",
      "Epoch 48/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5625 - loss: 0.9060 - val_accuracy: 0.4688 - val_loss: 2.4279\n",
      "Epoch 49/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.4921 - loss: 1.0792 - val_accuracy: 0.4375 - val_loss: 2.4740\n",
      "Epoch 50/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6562 - loss: 1.0360 - val_accuracy: 0.4479 - val_loss: 2.2433\n",
      "Epoch 51/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.4668 - loss: 1.1439 - val_accuracy: 0.4688 - val_loss: 2.8678\n",
      "Epoch 52/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3750 - loss: 1.0677 - val_accuracy: 0.5104 - val_loss: 2.4563\n",
      "Epoch 53/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.4862 - loss: 1.1354 - val_accuracy: 0.3854 - val_loss: 2.8377\n",
      "Epoch 54/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6250 - loss: 0.9872 - val_accuracy: 0.4479 - val_loss: 2.5351\n",
      "Epoch 55/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5197 - loss: 1.0896 - val_accuracy: 0.4479 - val_loss: 3.2660\n",
      "Epoch 56/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.0707 - val_accuracy: 0.4479 - val_loss: 3.3353\n",
      "Epoch 57/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4892 - loss: 1.0590 - val_accuracy: 0.4792 - val_loss: 2.8730\n",
      "Epoch 58/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.0809 - val_accuracy: 0.4688 - val_loss: 3.2211\n",
      "Epoch 59/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5322 - loss: 1.0663 - val_accuracy: 0.4688 - val_loss: 2.0717\n",
      "Epoch 60/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 0.9883 - val_accuracy: 0.4375 - val_loss: 2.4316\n",
      "Epoch 61/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5204 - loss: 1.0619 - val_accuracy: 0.5625 - val_loss: 2.6232\n",
      "Epoch 62/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4375 - loss: 1.1019 - val_accuracy: 0.4583 - val_loss: 2.9911\n",
      "Epoch 63/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5261 - loss: 1.0132 - val_accuracy: 0.4375 - val_loss: 2.5724\n",
      "Epoch 64/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4688 - loss: 1.0517 - val_accuracy: 0.4375 - val_loss: 3.9867\n",
      "Epoch 65/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.5124 - loss: 1.0608 - val_accuracy: 0.5312 - val_loss: 2.9374\n",
      "Epoch 66/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.1636 - val_accuracy: 0.4792 - val_loss: 3.4012\n",
      "Epoch 67/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5066 - loss: 1.0418 - val_accuracy: 0.4583 - val_loss: 4.6771\n",
      "Epoch 68/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.0840 - val_accuracy: 0.4896 - val_loss: 4.2024\n",
      "Epoch 69/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5112 - loss: 0.9963 - val_accuracy: 0.4792 - val_loss: 2.7559\n",
      "Epoch 70/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4688 - loss: 1.0586 - val_accuracy: 0.5000 - val_loss: 2.1603\n",
      "Epoch 71/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5269 - loss: 1.0877 - val_accuracy: 0.4271 - val_loss: 4.2940\n",
      "Epoch 72/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 1.0940 - val_accuracy: 0.4792 - val_loss: 3.2381\n",
      "Epoch 73/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.4792 - loss: 1.0923 - val_accuracy: 0.4688 - val_loss: 3.3682\n",
      "Epoch 74/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 1.1054 - val_accuracy: 0.4271 - val_loss: 3.8077\n",
      "Epoch 75/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4810 - loss: 1.0444 - val_accuracy: 0.4583 - val_loss: 3.5201\n",
      "Epoch 76/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.9603 - val_accuracy: 0.4375 - val_loss: 3.7110\n",
      "Epoch 77/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5577 - loss: 1.0090 - val_accuracy: 0.4583 - val_loss: 2.5020\n",
      "Epoch 78/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.1041 - val_accuracy: 0.4688 - val_loss: 2.8768\n",
      "Epoch 79/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5208 - loss: 1.0624 - val_accuracy: 0.4688 - val_loss: 3.4311\n",
      "Epoch 80/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.0285 - val_accuracy: 0.4583 - val_loss: 2.6668\n",
      "Epoch 81/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5647 - loss: 0.9889 - val_accuracy: 0.4375 - val_loss: 3.9998\n",
      "Epoch 82/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.0775 - val_accuracy: 0.3854 - val_loss: 5.0144\n",
      "Epoch 83/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5654 - loss: 1.0266 - val_accuracy: 0.4375 - val_loss: 5.2197\n",
      "Epoch 84/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.0732 - val_accuracy: 0.4062 - val_loss: 5.0708\n",
      "Epoch 85/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5421 - loss: 1.0565 - val_accuracy: 0.4375 - val_loss: 4.6436\n",
      "Epoch 86/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.9451 - val_accuracy: 0.4583 - val_loss: 4.4790\n",
      "Epoch 87/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.5232 - loss: 0.9994 - val_accuracy: 0.4479 - val_loss: 3.4649\n",
      "Epoch 88/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4062 - loss: 1.0700 - val_accuracy: 0.4688 - val_loss: 4.4291\n",
      "Epoch 89/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5362 - loss: 1.0241 - val_accuracy: 0.4375 - val_loss: 4.9561\n",
      "Epoch 90/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.0681 - val_accuracy: 0.4062 - val_loss: 4.2238\n",
      "Epoch 91/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.5330 - loss: 1.0081 - val_accuracy: 0.4583 - val_loss: 4.5295\n",
      "Epoch 92/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.0724 - val_accuracy: 0.4271 - val_loss: 4.3254\n",
      "Epoch 93/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5664 - loss: 1.0208 - val_accuracy: 0.4688 - val_loss: 5.8166\n",
      "Epoch 94/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4688 - loss: 1.0594 - val_accuracy: 0.4062 - val_loss: 6.3848\n",
      "Epoch 95/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.4883 - loss: 1.0704 - val_accuracy: 0.4271 - val_loss: 6.1639\n",
      "Epoch 96/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 0.8720 - val_accuracy: 0.4583 - val_loss: 6.6494\n",
      "Epoch 97/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5391 - loss: 1.0174 - val_accuracy: 0.4271 - val_loss: 9.1438\n",
      "Epoch 98/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4375 - loss: 1.2106 - val_accuracy: 0.3958 - val_loss: 8.1866\n",
      "Epoch 99/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.5114 - loss: 1.0561 - val_accuracy: 0.5208 - val_loss: 2.9991\n",
      "Epoch 100/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6538 - loss: 0.9446 - val_accuracy: 0.5208 - val_loss: 3.0800\n",
      "Epoch 101/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.4860 - loss: 1.1040 - val_accuracy: 0.4479 - val_loss: 3.6885\n",
      "Epoch 102/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.8685 - val_accuracy: 0.5000 - val_loss: 2.8696\n",
      "Epoch 103/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.4825 - loss: 1.0976 - val_accuracy: 0.4271 - val_loss: 3.8675\n",
      "Epoch 104/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4062 - loss: 1.0060 - val_accuracy: 0.3750 - val_loss: 3.8292\n",
      "Epoch 105/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5467 - loss: 1.0153 - val_accuracy: 0.3646 - val_loss: 6.0795\n",
      "Epoch 106/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.0031 - val_accuracy: 0.3646 - val_loss: 5.7966\n",
      "Epoch 107/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5080 - loss: 1.0736 - val_accuracy: 0.4375 - val_loss: 5.6021\n",
      "Epoch 108/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.9126 - val_accuracy: 0.4062 - val_loss: 6.7772\n",
      "Epoch 109/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5402 - loss: 1.0248 - val_accuracy: 0.4062 - val_loss: 7.7895\n",
      "Epoch 110/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.0297 - val_accuracy: 0.4792 - val_loss: 7.7109\n",
      "Epoch 111/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.5813 - loss: 0.9993 - val_accuracy: 0.3542 - val_loss: 10.2407\n",
      "Epoch 112/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5000 - loss: 1.1491 - val_accuracy: 0.4375 - val_loss: 8.9986\n",
      "Epoch 113/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5722 - loss: 0.9900 - val_accuracy: 0.4375 - val_loss: 8.9436\n",
      "Epoch 114/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.0326 - val_accuracy: 0.4167 - val_loss: 8.9812\n",
      "Epoch 115/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5505 - loss: 0.9597 - val_accuracy: 0.4062 - val_loss: 9.4609\n",
      "Epoch 116/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 0.9631 - val_accuracy: 0.4688 - val_loss: 8.5008\n",
      "Epoch 117/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5510 - loss: 0.9780 - val_accuracy: 0.4688 - val_loss: 7.0016\n",
      "Epoch 118/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.7673 - val_accuracy: 0.4167 - val_loss: 6.6816\n",
      "Epoch 119/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5419 - loss: 0.9566 - val_accuracy: 0.4271 - val_loss: 8.8731\n",
      "Epoch 120/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.9051 - val_accuracy: 0.4062 - val_loss: 8.3200\n",
      "Epoch 121/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.5492 - loss: 0.9584 - val_accuracy: 0.4062 - val_loss: 6.8666\n",
      "Epoch 122/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 0.8316 - val_accuracy: 0.4792 - val_loss: 6.0192\n",
      "Epoch 123/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5692 - loss: 0.9543 - val_accuracy: 0.4271 - val_loss: 5.6270\n",
      "Epoch 124/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4231 - loss: 1.2282 - val_accuracy: 0.3958 - val_loss: 4.1777\n",
      "Epoch 125/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5617 - loss: 0.9755 - val_accuracy: 0.4167 - val_loss: 3.3666\n",
      "Epoch 126/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.0462 - val_accuracy: 0.4583 - val_loss: 3.6197\n",
      "Epoch 127/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5202 - loss: 1.0356 - val_accuracy: 0.4062 - val_loss: 5.1715\n",
      "Epoch 128/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.8473 - val_accuracy: 0.4167 - val_loss: 5.1694\n",
      "Epoch 129/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.5755 - loss: 0.9793 - val_accuracy: 0.4167 - val_loss: 5.2403\n",
      "Epoch 130/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6250 - loss: 0.9143 - val_accuracy: 0.4062 - val_loss: 5.7583\n",
      "Epoch 131/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5185 - loss: 1.0087 - val_accuracy: 0.4375 - val_loss: 5.0896\n",
      "Epoch 132/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.0773 - val_accuracy: 0.3854 - val_loss: 5.8171\n",
      "Epoch 133/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5622 - loss: 0.9659 - val_accuracy: 0.4375 - val_loss: 4.0536\n",
      "Epoch 134/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4688 - loss: 1.0692 - val_accuracy: 0.3958 - val_loss: 4.6124\n",
      "Epoch 135/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5572 - loss: 1.0052 - val_accuracy: 0.4479 - val_loss: 5.1097\n",
      "Epoch 136/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6875 - loss: 0.9432 - val_accuracy: 0.4479 - val_loss: 3.8187\n",
      "Epoch 137/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5655 - loss: 0.9610 - val_accuracy: 0.4479 - val_loss: 5.7266\n",
      "Epoch 138/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.0522 - val_accuracy: 0.4583 - val_loss: 4.9697\n",
      "Epoch 139/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6315 - loss: 0.9337 - val_accuracy: 0.4271 - val_loss: 7.1698\n",
      "Epoch 140/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 1.1229 - val_accuracy: 0.3750 - val_loss: 7.5216\n",
      "Epoch 141/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5605 - loss: 0.9371 - val_accuracy: 0.4583 - val_loss: 8.9882\n",
      "Epoch 142/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6250 - loss: 1.0517 - val_accuracy: 0.4167 - val_loss: 11.0541\n",
      "Epoch 143/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5321 - loss: 1.0285 - val_accuracy: 0.3958 - val_loss: 11.5128\n",
      "Epoch 144/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.0848 - val_accuracy: 0.4167 - val_loss: 11.6024\n",
      "Epoch 145/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5666 - loss: 0.9454 - val_accuracy: 0.4271 - val_loss: 11.5706\n",
      "Epoch 146/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4062 - loss: 1.0930 - val_accuracy: 0.4375 - val_loss: 11.5689\n",
      "Epoch 147/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.5541 - loss: 1.0081 - val_accuracy: 0.4479 - val_loss: 8.3797\n",
      "Epoch 148/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 0.9260 - val_accuracy: 0.4167 - val_loss: 8.8766\n",
      "Epoch 149/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5984 - loss: 0.9269 - val_accuracy: 0.3958 - val_loss: 7.4849\n",
      "Epoch 150/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4231 - loss: 1.2220 - val_accuracy: 0.4062 - val_loss: 8.2787\n",
      "Epoch 151/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6133 - loss: 0.9070 - val_accuracy: 0.4375 - val_loss: 7.2292\n",
      "Epoch 152/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6562 - loss: 0.7805 - val_accuracy: 0.3646 - val_loss: 7.4981\n",
      "Epoch 153/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5895 - loss: 0.9044 - val_accuracy: 0.4375 - val_loss: 9.4000\n",
      "Epoch 154/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 1.0446 - val_accuracy: 0.4167 - val_loss: 9.2980\n",
      "Epoch 155/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5806 - loss: 0.9502 - val_accuracy: 0.4479 - val_loss: 8.3505\n",
      "Epoch 156/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4688 - loss: 1.1096 - val_accuracy: 0.4271 - val_loss: 10.2314\n",
      "Epoch 157/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5627 - loss: 0.9448 - val_accuracy: 0.4271 - val_loss: 12.6035\n",
      "Epoch 158/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3438 - loss: 1.2607 - val_accuracy: 0.3854 - val_loss: 13.9319\n",
      "Epoch 159/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.6261 - loss: 0.9150 - val_accuracy: 0.4375 - val_loss: 5.3611\n",
      "Epoch 160/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 0.8389 - val_accuracy: 0.4271 - val_loss: 4.5688\n",
      "Epoch 161/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5882 - loss: 0.9369 - val_accuracy: 0.5208 - val_loss: 2.3225\n",
      "Epoch 162/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5625 - loss: 0.8881 - val_accuracy: 0.4688 - val_loss: 2.9749\n",
      "Epoch 163/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5911 - loss: 0.9549 - val_accuracy: 0.4583 - val_loss: 3.1761\n",
      "Epoch 164/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.8804 - val_accuracy: 0.5208 - val_loss: 2.7875\n",
      "Epoch 165/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.5612 - loss: 0.9697 - val_accuracy: 0.4479 - val_loss: 4.3129\n",
      "Epoch 166/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4615 - loss: 1.0040 - val_accuracy: 0.4479 - val_loss: 4.9229\n",
      "Epoch 167/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5592 - loss: 0.9255 - val_accuracy: 0.4688 - val_loss: 4.6325\n",
      "Epoch 168/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.0568 - val_accuracy: 0.4479 - val_loss: 5.1435\n",
      "Epoch 169/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.6195 - loss: 0.8952 - val_accuracy: 0.5104 - val_loss: 4.5531\n",
      "Epoch 170/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5000 - loss: 1.0003 - val_accuracy: 0.4792 - val_loss: 4.8183\n",
      "Epoch 171/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.5747 - loss: 0.9026 - val_accuracy: 0.4167 - val_loss: 6.5232\n",
      "Epoch 172/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 1.1337 - val_accuracy: 0.3750 - val_loss: 5.9916\n",
      "Epoch 173/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5845 - loss: 0.9202 - val_accuracy: 0.4167 - val_loss: 6.6017\n",
      "Epoch 174/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5385 - loss: 0.8619 - val_accuracy: 0.4271 - val_loss: 6.7005\n",
      "Epoch 175/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.5947 - loss: 0.9143 - val_accuracy: 0.4375 - val_loss: 8.6379\n",
      "Epoch 176/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6538 - loss: 0.7948 - val_accuracy: 0.3854 - val_loss: 6.7502\n",
      "Epoch 177/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5825 - loss: 0.9190 - val_accuracy: 0.4583 - val_loss: 9.0955\n",
      "Epoch 178/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7812 - loss: 0.7276 - val_accuracy: 0.4167 - val_loss: 8.8597\n",
      "Epoch 179/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6033 - loss: 0.8861 - val_accuracy: 0.4271 - val_loss: 7.6900\n",
      "Epoch 180/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 0.9513 - val_accuracy: 0.4375 - val_loss: 9.0544\n",
      "Epoch 181/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6167 - loss: 0.8998 - val_accuracy: 0.3750 - val_loss: 8.9721\n",
      "Epoch 182/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6875 - loss: 0.8116 - val_accuracy: 0.4375 - val_loss: 6.3986\n",
      "Epoch 183/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6029 - loss: 0.8920 - val_accuracy: 0.4167 - val_loss: 11.8785\n",
      "Epoch 184/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6250 - loss: 1.0363 - val_accuracy: 0.3958 - val_loss: 8.9904\n",
      "Epoch 185/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6251 - loss: 0.8945 - val_accuracy: 0.4062 - val_loss: 7.9874\n",
      "Epoch 186/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4062 - loss: 1.0848 - val_accuracy: 0.4479 - val_loss: 8.0481\n",
      "Epoch 187/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.5959 - loss: 0.9277 - val_accuracy: 0.4167 - val_loss: 6.4005\n",
      "Epoch 188/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.8129 - val_accuracy: 0.4062 - val_loss: 5.7917\n",
      "Epoch 189/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.5407 - loss: 1.0340 - val_accuracy: 0.4583 - val_loss: 3.4378\n",
      "Epoch 190/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 0.7945 - val_accuracy: 0.4479 - val_loss: 2.9313\n",
      "Epoch 191/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.6287 - loss: 0.9396 - val_accuracy: 0.4896 - val_loss: 1.8101\n",
      "Epoch 192/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 0.9257 - val_accuracy: 0.4792 - val_loss: 2.1052\n",
      "Epoch 193/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5849 - loss: 0.8822 - val_accuracy: 0.5000 - val_loss: 2.8271\n",
      "Epoch 194/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 1.1436 - val_accuracy: 0.6146 - val_loss: 2.2700\n",
      "Epoch 195/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6004 - loss: 0.9274 - val_accuracy: 0.5000 - val_loss: 3.0882\n",
      "Epoch 196/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4375 - loss: 1.1446 - val_accuracy: 0.4792 - val_loss: 3.3437\n",
      "Epoch 197/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5918 - loss: 0.9146 - val_accuracy: 0.4792 - val_loss: 3.3186\n",
      "Epoch 198/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.7274 - val_accuracy: 0.5000 - val_loss: 3.3367\n",
      "Epoch 199/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6057 - loss: 0.8998 - val_accuracy: 0.4688 - val_loss: 2.9300\n",
      "Epoch 200/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6250 - loss: 0.9767 - val_accuracy: 0.4688 - val_loss: 3.7159\n",
      "Epoch 201/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6085 - loss: 0.8854 - val_accuracy: 0.4792 - val_loss: 4.4065\n",
      "Epoch 202/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.8021 - val_accuracy: 0.4375 - val_loss: 5.4159\n",
      "Epoch 203/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.5880 - loss: 0.9225 - val_accuracy: 0.4583 - val_loss: 5.2925\n",
      "Epoch 204/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 0.8804 - val_accuracy: 0.4167 - val_loss: 5.2793\n",
      "Epoch 205/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6185 - loss: 0.9080 - val_accuracy: 0.4479 - val_loss: 5.5487\n",
      "Epoch 206/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 0.8605 - val_accuracy: 0.4583 - val_loss: 5.6867\n",
      "Epoch 207/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6221 - loss: 0.8576 - val_accuracy: 0.4167 - val_loss: 7.5350\n",
      "Epoch 208/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.9963 - val_accuracy: 0.4271 - val_loss: 7.3044\n",
      "Epoch 209/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5981 - loss: 0.9180 - val_accuracy: 0.4271 - val_loss: 5.9399\n",
      "Epoch 210/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 0.7955 - val_accuracy: 0.4167 - val_loss: 6.3712\n",
      "Epoch 211/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.6001 - loss: 0.9083 - val_accuracy: 0.3958 - val_loss: 8.1534\n",
      "Epoch 212/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.7955 - val_accuracy: 0.3854 - val_loss: 6.0806\n",
      "Epoch 213/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5933 - loss: 0.9032 - val_accuracy: 0.4375 - val_loss: 8.3210\n",
      "Epoch 214/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6875 - loss: 0.7682 - val_accuracy: 0.4583 - val_loss: 7.2249\n",
      "Epoch 215/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.5917 - loss: 0.8813 - val_accuracy: 0.4375 - val_loss: 7.8578\n",
      "Epoch 216/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.9008 - val_accuracy: 0.4271 - val_loss: 8.8928\n",
      "Epoch 217/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.6292 - loss: 0.8762 - val_accuracy: 0.3854 - val_loss: 11.1881\n",
      "Epoch 218/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.7817 - val_accuracy: 0.4375 - val_loss: 7.0377\n",
      "Epoch 219/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 0.6092 - loss: 0.8805 - val_accuracy: 0.3854 - val_loss: 8.5878\n",
      "Epoch 220/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6562 - loss: 0.8734 - val_accuracy: 0.4688 - val_loss: 8.5280\n",
      "Epoch 221/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.5619 - loss: 0.9320 - val_accuracy: 0.4062 - val_loss: 7.1628\n",
      "Epoch 222/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6250 - loss: 0.9014 - val_accuracy: 0.4271 - val_loss: 7.8626\n",
      "Epoch 223/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.6306 - loss: 0.8709 - val_accuracy: 0.3854 - val_loss: 6.6767\n",
      "Epoch 224/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.8774 - val_accuracy: 0.4583 - val_loss: 6.0964\n",
      "Epoch 225/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.6469 - loss: 0.8204 - val_accuracy: 0.4062 - val_loss: 8.3809\n",
      "Epoch 226/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 0.9460 - val_accuracy: 0.4271 - val_loss: 8.3563\n",
      "Epoch 227/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.6364 - loss: 0.8469 - val_accuracy: 0.4792 - val_loss: 7.3639\n",
      "Epoch 228/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.6475 - val_accuracy: 0.4479 - val_loss: 9.2025\n",
      "Epoch 229/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.6344 - loss: 0.8139 - val_accuracy: 0.3958 - val_loss: 16.1961\n",
      "Epoch 230/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.7065 - val_accuracy: 0.3854 - val_loss: 12.6959\n",
      "Epoch 231/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.6639 - loss: 0.8629 - val_accuracy: 0.3958 - val_loss: 13.9184\n",
      "Epoch 232/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 0.8829 - val_accuracy: 0.3958 - val_loss: 13.1234\n",
      "Epoch 233/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.6701 - loss: 0.8442 - val_accuracy: 0.4583 - val_loss: 11.3347\n",
      "Epoch 234/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.6863 - val_accuracy: 0.3542 - val_loss: 12.2136\n",
      "Epoch 235/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6209 - loss: 0.8297 - val_accuracy: 0.4583 - val_loss: 12.0842\n",
      "Epoch 236/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 0.7722 - val_accuracy: 0.4479 - val_loss: 12.0139\n",
      "Epoch 237/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6107 - loss: 0.8569 - val_accuracy: 0.4167 - val_loss: 11.9460\n",
      "Epoch 238/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 1.0313 - val_accuracy: 0.5104 - val_loss: 9.9006\n",
      "Epoch 239/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6219 - loss: 0.8531 - val_accuracy: 0.4271 - val_loss: 11.6562\n",
      "Epoch 240/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 0.8070 - val_accuracy: 0.3542 - val_loss: 12.7524\n",
      "Epoch 241/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6196 - loss: 0.8687 - val_accuracy: 0.4167 - val_loss: 12.0351\n",
      "Epoch 242/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8438 - loss: 0.5419 - val_accuracy: 0.3646 - val_loss: 13.8161\n",
      "Epoch 243/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6650 - loss: 0.8307 - val_accuracy: 0.4167 - val_loss: 16.7054\n",
      "Epoch 244/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7188 - loss: 0.7608 - val_accuracy: 0.4062 - val_loss: 14.3418\n",
      "Epoch 245/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6107 - loss: 0.9020 - val_accuracy: 0.3854 - val_loss: 16.5528\n",
      "Epoch 246/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.6131 - val_accuracy: 0.3750 - val_loss: 14.0810\n",
      "Epoch 247/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6121 - loss: 0.8761 - val_accuracy: 0.4583 - val_loss: 13.0293\n",
      "Epoch 248/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5938 - loss: 0.8379 - val_accuracy: 0.4479 - val_loss: 11.0481\n",
      "Epoch 249/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6251 - loss: 0.8706 - val_accuracy: 0.4688 - val_loss: 12.1680\n",
      "Epoch 250/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8750 - loss: 0.5436 - val_accuracy: 0.4062 - val_loss: 13.2992\n",
      "Epoch 251/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 0.6985 - loss: 0.7557 - val_accuracy: 0.4271 - val_loss: 7.5683\n",
      "Epoch 252/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.6395 - val_accuracy: 0.3958 - val_loss: 11.3181\n",
      "Epoch 253/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6401 - loss: 0.7989 - val_accuracy: 0.4271 - val_loss: 7.8915\n",
      "Epoch 254/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.7656 - val_accuracy: 0.4271 - val_loss: 8.3972\n",
      "Epoch 255/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6763 - loss: 0.7801 - val_accuracy: 0.4375 - val_loss: 9.4583\n",
      "Epoch 256/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 0.9086 - val_accuracy: 0.3958 - val_loss: 12.0416\n",
      "Epoch 257/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6371 - loss: 0.8088 - val_accuracy: 0.3854 - val_loss: 11.9971\n",
      "Epoch 258/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.7063 - val_accuracy: 0.3750 - val_loss: 13.2062\n",
      "Epoch 259/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.6335 - loss: 0.7988 - val_accuracy: 0.4167 - val_loss: 12.9295\n",
      "Epoch 260/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8438 - loss: 0.5197 - val_accuracy: 0.4167 - val_loss: 11.3492\n",
      "Epoch 261/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6414 - loss: 0.8594 - val_accuracy: 0.4479 - val_loss: 7.5183\n",
      "Epoch 262/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6562 - loss: 0.7842 - val_accuracy: 0.4375 - val_loss: 10.2386\n",
      "Epoch 263/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6264 - loss: 0.8147 - val_accuracy: 0.4583 - val_loss: 7.4328\n",
      "Epoch 264/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5938 - loss: 0.8127 - val_accuracy: 0.4688 - val_loss: 7.3777\n",
      "Epoch 265/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.6272 - loss: 0.8377 - val_accuracy: 0.4375 - val_loss: 6.1607\n",
      "Epoch 266/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6250 - loss: 0.9286 - val_accuracy: 0.4792 - val_loss: 7.1252\n",
      "Epoch 267/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6438 - loss: 0.7911 - val_accuracy: 0.5104 - val_loss: 9.5538\n",
      "Epoch 268/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6250 - loss: 0.8479 - val_accuracy: 0.4583 - val_loss: 9.9408\n",
      "Epoch 269/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6202 - loss: 0.8443 - val_accuracy: 0.4062 - val_loss: 10.8656\n",
      "Epoch 270/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.6697 - val_accuracy: 0.3854 - val_loss: 12.4212\n",
      "Epoch 271/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6766 - loss: 0.7723 - val_accuracy: 0.4375 - val_loss: 10.8532\n",
      "Epoch 272/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6923 - loss: 0.7649 - val_accuracy: 0.4583 - val_loss: 10.1473\n",
      "Epoch 273/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6321 - loss: 0.7914 - val_accuracy: 0.4896 - val_loss: 10.2377\n",
      "Epoch 274/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5312 - loss: 0.9753 - val_accuracy: 0.4271 - val_loss: 12.4292\n",
      "Epoch 275/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6830 - loss: 0.7494 - val_accuracy: 0.4688 - val_loss: 12.3750\n",
      "Epoch 276/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5625 - loss: 0.9515 - val_accuracy: 0.4271 - val_loss: 13.2420\n",
      "Epoch 277/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5798 - loss: 0.8877 - val_accuracy: 0.4062 - val_loss: 11.7978\n",
      "Epoch 278/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5938 - loss: 0.8885 - val_accuracy: 0.4167 - val_loss: 10.0040\n",
      "Epoch 279/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6614 - loss: 0.8207 - val_accuracy: 0.4479 - val_loss: 8.2782\n",
      "Epoch 280/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7500 - loss: 0.6038 - val_accuracy: 0.3854 - val_loss: 10.0148\n",
      "Epoch 281/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6542 - loss: 0.8206 - val_accuracy: 0.3750 - val_loss: 8.7529\n",
      "Epoch 282/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5938 - loss: 0.9735 - val_accuracy: 0.4167 - val_loss: 9.5505\n",
      "Epoch 283/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.6410 - loss: 0.7666 - val_accuracy: 0.4375 - val_loss: 9.6378\n",
      "Epoch 284/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.7501 - val_accuracy: 0.5000 - val_loss: 7.4316\n",
      "Epoch 285/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.6795 - loss: 0.7761 - val_accuracy: 0.4375 - val_loss: 8.6472\n",
      "Epoch 286/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.7570 - val_accuracy: 0.4167 - val_loss: 12.7688\n",
      "Epoch 287/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6715 - loss: 0.7815 - val_accuracy: 0.4062 - val_loss: 9.3555\n",
      "Epoch 288/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5312 - loss: 0.8560 - val_accuracy: 0.4167 - val_loss: 12.6161\n",
      "Epoch 289/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6773 - loss: 0.7584 - val_accuracy: 0.4271 - val_loss: 11.5312\n",
      "Epoch 290/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6562 - loss: 0.8644 - val_accuracy: 0.4062 - val_loss: 9.6649\n",
      "Epoch 291/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6886 - loss: 0.7435 - val_accuracy: 0.4688 - val_loss: 3.0081\n",
      "Epoch 292/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6250 - loss: 0.9567 - val_accuracy: 0.5417 - val_loss: 2.9764\n",
      "Epoch 293/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6784 - loss: 0.7816 - val_accuracy: 0.4583 - val_loss: 6.5650\n",
      "Epoch 294/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 0.8025 - val_accuracy: 0.4479 - val_loss: 6.0184\n",
      "Epoch 295/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.6466 - loss: 0.7955 - val_accuracy: 0.5208 - val_loss: 8.3010\n",
      "Epoch 296/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7188 - loss: 0.6940 - val_accuracy: 0.4062 - val_loss: 9.5572\n",
      "Epoch 297/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.6803 - loss: 0.7694 - val_accuracy: 0.4583 - val_loss: 8.7800\n",
      "Epoch 298/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.6565 - val_accuracy: 0.4792 - val_loss: 8.6973\n",
      "Epoch 299/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.6173 - loss: 0.8331 - val_accuracy: 0.4375 - val_loss: 10.4683\n",
      "Epoch 300/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.9192 - val_accuracy: 0.4167 - val_loss: 13.2969\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=300,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=train_generator.samples // 32,\n",
    "    validation_steps=validation_generator.samples // 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 0.4312 - loss: 14.7788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 45.30%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "model.save('solar_fault_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
